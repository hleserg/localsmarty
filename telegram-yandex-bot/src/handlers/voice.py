import logging
import io
from telegram import Update
from io import BytesIO
from telegram.ext import ContextTypes
from services.neuroapi_client import get_gpt_response
from handlers.commands import _reply_md_v2_safe
from services.speech_client import speech_client
from config import config
from utils.logger import log_message, log_response

logger = logging.getLogger(__name__)

async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handler for voice messages"""
    if not config.ENABLE_VOICE:
        if update.message and update.effective_chat and update.effective_user:
            await _reply_md_v2_safe(update, "–ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            log_response(update.effective_chat.id, "TEXT", True)
        return

    if not update.message or not update.effective_chat or not update.effective_user or not update.message.voice:
        return

    chat_id = update.effective_chat.id
    user_id = update.effective_user.id
    username = update.effective_user.username
    voice = update.message.voice
    message_id = update.message.message_id

    # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥—è—â–µ–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    log_message(
        chat_id=chat_id,
        user_id=user_id,
        username=username,
        message_type="VOICE",
        content=f"Voice message, duration: {voice.duration}s, file_id: {voice.file_id}",
        message_id=message_id
    )

    # Check duration limit
    if voice.duration > config.AUDIO_MAX_DURATION_SEC:
        await _reply_md_v2_safe(update, f"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å. {config.AUDIO_MAX_DURATION_SEC} —Å–µ–∫). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        log_response(chat_id, "TEXT", True)
        return

    try:
        # Download voice file
        voice_file = await context.bot.get_file(voice.file_id)
        voice_bytes = io.BytesIO()
        await voice_file.download_to_memory(out=voice_bytes)
        audio_data = voice_bytes.getvalue()

        logger.info(f"Downloaded voice file, size: {len(audio_data)} bytes")

        # Convert speech to text
        await _reply_md_v2_safe(update, "üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        log_response(chat_id, "TEXT", True)

        recognized_text = speech_client.speech_to_text(audio_data)
        if not recognized_text:
            await _reply_md_v2_safe(update, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            log_response(chat_id, "TEXT", True)
            return

        logger.info(f"Recognized text: {recognized_text[:100]}...")

        # Show recognized text to user
        await _reply_md_v2_safe(update, f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {recognized_text}")
        log_response(chat_id, "TEXT", True)

        # Get GPT response
        gpt_response = get_gpt_response(recognized_text, chat_id)

        # Send text response
        await _reply_md_v2_safe(update, f"ü§ñ {gpt_response}")
        log_response(chat_id, "TEXT", True)

        # Optionally send voice response (TTS)
        if config.ENABLE_TTS_REPLY:
            tts_audio = speech_client.text_to_speech(gpt_response)
            if tts_audio:
                await update.message.reply_voice(voice=BytesIO(tts_audio))
                log_response(chat_id, "VOICE", True)
            else:
                logger.warning("TTS generation failed; sending text only")
                log_response(chat_id, "VOICE", False, "TTS generation failed")

        logger.info(f"Successfully processed voice message for chat {chat_id}")

    except Exception as e:
        logger.error(f"Error processing voice message for chat {chat_id}: {str(e)}")
        log_response(chat_id, "TEXT", False, str(e))
        if update.message:
            await _reply_md_v2_safe(update, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç.")

async def handle_audio_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handler for audio messages (similar to voice but for audio files)"""
    if not config.ENABLE_VOICE:
        if update.message:
            await _reply_md_v2_safe(update, "–ê—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return
    
    # For simplicity, redirect audio to voice handler
    # In a more sophisticated implementation, we might handle different audio formats
    await handle_voice_message(update, context)