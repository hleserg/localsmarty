import logging
import io
from telegram import Update
from io import BytesIO
from telegram.ext import ContextTypes
from services.yandex_client import get_gpt_response
from handlers.commands import _reply_md_v2_safe
from services.speech_client import speech_client
from config import config

logger = logging.getLogger(__name__)

async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handler for voice messages"""
    if not config.ENABLE_VOICE:
        if update.message:
            await _reply_md_v2_safe(update, "–ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return

    if not update.message or not update.effective_chat or not update.message.voice:
        return

    chat_id = update.effective_chat.id
    voice = update.message.voice

    logger.info(f"Received voice message from chat {chat_id}, duration: {voice.duration}s")

    # Check duration limit
    if voice.duration > config.AUDIO_MAX_DURATION_SEC:
        await _reply_md_v2_safe(update, f"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å. {config.AUDIO_MAX_DURATION_SEC} —Å–µ–∫). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return

    try:
        # Download voice file
        voice_file = await context.bot.get_file(voice.file_id)
        voice_bytes = io.BytesIO()
        await voice_file.download_to_memory(out=voice_bytes)
        audio_data = voice_bytes.getvalue()

        logger.info(f"Downloaded voice file, size: {len(audio_data)} bytes")

        # Convert speech to text
        await _reply_md_v2_safe(update, "üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")

        recognized_text = speech_client.speech_to_text(audio_data)
        if not recognized_text:
            await _reply_md_v2_safe(update, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            return

        logger.info(f"Recognized text: {recognized_text[:100]}...")

        # Show recognized text to user
        await _reply_md_v2_safe(update, f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {recognized_text}")

        # Get GPT response
        gpt_response = get_gpt_response(recognized_text, chat_id)

        # Send text response
        await _reply_md_v2_safe(update, f"ü§ñ {gpt_response}")

        # Optionally send voice response (TTS)
        if config.ENABLE_TTS_REPLY:
            tts_audio = speech_client.text_to_speech(gpt_response)
            if tts_audio:
                await update.message.reply_voice(voice=BytesIO(tts_audio))
            else:
                logger.warning("TTS generation failed; sending text only")

        logger.info(f"Successfully processed voice message for chat {chat_id}")

    except Exception as e:
        logger.error(f"Error processing voice message for chat {chat_id}: {str(e)}")
        if update.message:
            await _reply_md_v2_safe(update, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç.")

async def handle_audio_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handler for audio messages (similar to voice but for audio files)"""
    if not config.ENABLE_VOICE:
        if update.message:
            await _reply_md_v2_safe(update, "–ê—É–¥–∏–æ—Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
        return
    
    # For simplicity, redirect audio to voice handler
    # In a more sophisticated implementation, we might handle different audio formats
    await handle_voice_message(update, context)